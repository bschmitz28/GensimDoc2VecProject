{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q76cdKS4k8YJ"
   },
   "source": [
    "# Step 1: Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mxLnESmyk8YM"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "c_WQkD26k8YN"
   },
   "outputs": [],
   "source": [
    "#READING A DATA FILE (TAGS range from 0 to len(data))\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "\n",
    "#THIS CREATES A TRAINING CORPUS\n",
    "train_corpus = list(read_corpus(\"/train.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THbglzC1k8YO",
    "outputId": "4de8a8ca-2241-4c53-dc32-a15668864147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TES7UuVk8YO"
   },
   "source": [
    "INSTANTIATE THE GENSIM DOC2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "2gLNcaxRk8YP"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "522VXU79k8YP"
   },
   "source": [
    "Create the Vocabulary, Train the model using train_corpus, Store vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "SaAafu21k8YQ"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "train_vectors = []\n",
    "for i in range(len(train_corpus)):\n",
    "    vector = model.infer_vector(train_corpus[i].words)\n",
    "    train_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdD4dGy0BJLD"
   },
   "source": [
    "Stack vectors, read training labels as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXLibBXCk8YS",
    "outputId": "ae820499-6953-4c40-d7f2-80105971f6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 50)\n",
      "(963,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = np.vstack(X)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = pd.read_table('/trainlabels.txt', header = None)\n",
    "y_train.columns = ['y']\n",
    "y_train = np.array(y_train['y'])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay2Xvfozk8YU"
   },
   "source": [
    "Repeat the above steps with the validation and test data (no need to retrain the genism model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoNooYqHk8YU",
    "outputId": "ccf3b449-ec75-4809-f02d-0dc670e167f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_corpus = list(read_corpus(\"/validation.txt\"))\n",
    "len(validation_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PuVWAE4-k8YU"
   },
   "outputs": [],
   "source": [
    "val_vectors = []\n",
    "\n",
    "for i in range(len(validation_corpus)):\n",
    "    vector = model.infer_vector(validation_corpus[i].words)\n",
    "    val_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tk82jQEhk8YU",
    "outputId": "a2b451a5-fc2a-4da5-f4cb-1942a5ab0595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 50)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "X_validation = np.vstack(val_vectors)\n",
    "print(X_validation.shape)\n",
    "\n",
    "y_validation = pd.read_table('/validationlabels.txt', header = None)\n",
    "y_validation.columns = ['y']\n",
    "y_validation = np.array(y_validation['y'])\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaZ6rsbek8YV",
    "outputId": "0505234d-4060-410b-f4ea-9a04ba7416d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = list(read_corpus(\"/test.txt\"))\n",
    "len(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "KJsiHan5k8YV"
   },
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "\n",
    "for i in range(len(test_corpus)):\n",
    "    vector = model.infer_vector(test_corpus[i].words)\n",
    "    test_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Hn25_TDk8YV",
    "outputId": "5a99619f-c1e7-44f9-f231-87850dbb801c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 50)\n",
      "(122,)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.vstack(test_vectors)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = pd.read_table('/testlabels.txt', header = None)\n",
    "y_test.columns = ['y']\n",
    "y_test = np.array(y_test['y'])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN18mD2xk8YW"
   },
   "source": [
    "# Step 2: Train classifiers and test using validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4H5eyamk8YW"
   },
   "source": [
    "1. Logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN6Xi4ASk8YW"
   },
   "source": [
    "First do not set any penalty to set a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E56bDmyjk8YW",
    "outputId": "5b5e8670-9c92-49dc-be59-7791bb4ee2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Penalty 0.4893617021276596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_validation)\n",
    "print(\"No Penalty\", f1_score(y_pred, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcEO8O4Xk8YW"
   },
   "source": [
    "Test model with an L1, L2, and Elasticnet penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s14S_x-sk8YX",
    "outputId": "139c8e5d-0a29-46a1-be36-b26355e9ba65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 penalty 0.4946236559139786\n",
      "L2 penalty 0.4893617021276596\n",
      "Elasticnet penality 0.4946236559139786\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000, penalty = 'l1')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_validation)\n",
    "print(\"L1 penalty\",f1_score(y_pred, y_validation))\n",
    "\n",
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000, penalty = 'l2')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_validation)\n",
    "print(\"L2 penalty\",f1_score(y_pred, y_validation))\n",
    "\n",
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000, penalty = 'elasticnet', l1_ratio = 0.7)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_validation)\n",
    "print(\"Elasticnet penality\",f1_score(y_pred, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1FGMUqIk8YX"
   },
   "source": [
    "Increase in F1 score for L1 and Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhNojfk3k8YY"
   },
   "source": [
    "2. Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "d7eF90yPk8YY"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_azjxgwSk8YY",
    "outputId": "b58e823c-a7c6-4b4f-f673-58ee63503ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6870229007633588\n",
      "0.6607142857142857\n",
      "0.6846846846846847\n",
      "0.6666666666666666\n",
      "0.6964285714285715\n",
      "0.6542056074766355\n",
      "0.6371681415929203\n",
      "0.6407766990291263\n",
      "0.6481481481481481\n",
      "0.5686274509803921\n",
      "0.6226415094339623\n",
      "0.6846846846846847\n",
      "0.6728971962616823\n",
      "0.6336633663366336\n",
      "The best F1 score of 0.6964285714285715 with an optimal depth of 5\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(1, 15):\n",
    "    clf = RandomForestClassifier(max_depth=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_validation)\n",
    "    score = f1_score(y_pred, y_validation)\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "best_depth = (scores.index(max(scores))+1)\n",
    "\n",
    "print('The best F1 score of', max(scores), \"with an optimal depth of\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3tR_Nfmk8YY"
   },
   "source": [
    "Random Forest classifier is out performing Logistic Regression for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mTEbFKRk8YY"
   },
   "source": [
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZEVEHcZk8YZ"
   },
   "source": [
    "Constructing a loop to see best number of hidden layers for one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp51-ot8k8YZ",
    "outputId": "18a7a3cd-6984-43cf-bdc9-5dc03e9a9af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5436893203883496\n",
      "0.6153846153846154\n",
      "0.5714285714285715\n",
      "0.43478260869565216\n",
      "0.5656565656565657\n",
      "0.5154639175257731\n",
      "0.5544554455445545\n",
      "The optimal index was 2 and the best F1 score for 1 hidden node within 1 hidden layer was 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "scores = []\n",
    "for i in range(1,22, 3):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (i,), activation = 'tanh', max_iter=2000).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_validation)\n",
    "    score = f1_score(y_pred, y_validation)\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "best_index = (scores.index(max(scores)) + 1)\n",
    "print('The optimal index was', best_index, 'and the best F1 score for 1 hidden node within 1 hidden layer was', max(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lx0WT0tNk8YZ"
   },
   "source": [
    "Testing 2 and 3 hidden nodes as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KF3TX_izk8YZ",
    "outputId": "1b58d4ee-079e-4361-bf6b-927c4836d9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4893617021276596\n",
      "0.5050505050505051\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(2,4):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (i,), activation = 'tanh', max_iter=2000).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_validation)\n",
    "    score = f1_score(y_pred, y_validation)\n",
    "    print(score)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMGNs8m5k8YZ"
   },
   "source": [
    "1 Hidden Node yielded the best F1 score compared to 2 and 3 but the 3rd one was better than the 2nd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M8Rp3Dgk8YZ"
   },
   "source": [
    "Repeating the same procedure with the number of hidden layers using the 3 hidden nodes from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biOE_BZJk8YZ",
    "outputId": "7bb21f5c-fcdd-476f-f517-79290d6e1036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607843137254902\n",
      "0.5052631578947367\n",
      "0.46808510638297873\n",
      "0.54\n",
      "0.5252525252525252\n",
      "0.5283018867924527\n",
      "0.5825242718446603\n",
      "The optimal index was 1 With an F1 score of 0.607843137254902 for 3 hidden nodes\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(1,22, 3):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (3, i), activation = 'tanh', max_iter=2000).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_validation)\n",
    "    score = f1_score(y_pred, y_validation)\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "    \n",
    "best_index = (scores.index(max(scores)) + 1)\n",
    "print('The optimal index was', best_index, 'With an F1 score of', max(scores),'for 3 hidden nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSHTWz88k8Ya"
   },
   "source": [
    "Testing with 2 and 3 hidden layers using 3 hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKodlHgxk8Ya",
    "outputId": "9988d31a-94f4-4a96-c3eb-533c0c8d8a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4545454545454545\n",
      "0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(2,4):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (3,i), activation = 'tanh', max_iter=2000).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_validation)\n",
    "    score = f1_score(y_pred, y_validation)\n",
    "    print(score)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvV0Tkktk8Ya"
   },
   "source": [
    "The performance descreased. Will use 1 hidden nodes within 1 hidden layer on the testing data since that was the highest F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8RgTP5zk8Ya"
   },
   "source": [
    "# Step 3: Evaluate performance on Test set using best parameters found from Validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UViM3g_gk8Ya"
   },
   "source": [
    "1. Test the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Mbll0kLck8Ya"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAl7vSuJk8Ya",
    "outputId": "7c4bf7bd-41b6-4512-e961-6a91d29d6e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6666666666666666\n",
      "Precision:  0.5964912280701754\n",
      "Recall:  0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000, penalty = 'l1') \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('F1 score: ', f1_score(y_pred, y_test))\n",
    "print('Precision: ', precision_score(y_pred, y_test))\n",
    "print('Recall: ', recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maZH4Ub8YSyI"
   },
   "source": [
    "Above using l1 penalty, below using elasticnet penalty since both were F1 scores were tied for highest on Validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkRjjotdYQl3",
    "outputId": "f2dac83a-539e-495f-dc5c-a4a5b98355b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6666666666666666\n",
      "Precision:  0.5964912280701754\n",
      "Recall:  0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver = 'saga', max_iter = 5000, penalty = 'elasticnet',l1_ratio = 0.7) \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('F1 score: ', f1_score(y_pred, y_test))\n",
    "print('Precision: ', precision_score(y_pred, y_test))\n",
    "print('Recall: ', recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkMZKepSk8Yb"
   },
   "source": [
    "Performance on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6JslO7Ak8Yb",
    "outputId": "eef9cf77-31d2-4c70-9931-96fded51880f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.8051434223541049\n",
      "Precision = 0.814\n",
      "Recall = 0.7964774951076321\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "print('F1 score =', f1_score(y_pred, y_train))\n",
    "print('Precision =', precision_score(y_pred, y_train))\n",
    "print('Recall =', recall_score(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFTnN3oGk8Yb"
   },
   "source": [
    "Performance on Training set is best, much better than the Test set. However, the performance on the Validation sets were the worst. Slightly overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO_jvfOEk8Yb"
   },
   "source": [
    "2. Test the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifmX6OzYk8Yb",
    "outputId": "fa33befb-65bc-47f5-9a43-6032f81332c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.7387387387387387\n",
      "Precision = 0.7192982456140351\n",
      "Recall = 0.7592592592592593\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('F1 score =', f1_score(y_pred, y_test))\n",
    "print('Precision =', precision_score(y_pred, y_test))\n",
    "print('Recall =', recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sQXBieok8Yb"
   },
   "source": [
    "Performance on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOvK0T7ak8Yb",
    "outputId": "a5834cc4-cbea-44ff-e458-ef91dc053512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.9103313840155945\n",
      "Precision = 0.934\n",
      "Recall = 0.8878326996197718\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "print('F1 score =', f1_score(y_pred, y_train))\n",
    "print('Precision =', precision_score(y_pred, y_train))\n",
    "print('Recall =', recall_score(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NmEQq88k8Yb"
   },
   "source": [
    "This one is also slightly overfitting the data since the performance of the Training set is higher than the Test set. However, the Random Forest classifier gives better performance than Logistic Regression for Test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGx_MDn3k8Yb"
   },
   "source": [
    "3. Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_a4tB1T1k8Yc",
    "outputId": "a46ec068-dae1-4471-ac47-59af06d35625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6846846846846847\n",
      "Precision = 0.6666666666666666\n",
      "Recall = 0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = (1, 1), activation = 'tanh', max_iter=2000).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('F1 score =', f1_score(y_pred, y_test))\n",
    "print('Precision =', precision_score(y_pred, y_test))\n",
    "print('Recall =', recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ARdt-L2k8Yc"
   },
   "source": [
    "Check Performance on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zm8gWwuvk8Yc",
    "outputId": "cb82deee-9ac2-4241-a219-2dd8e5f546ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.8282630029440627\n",
      "Precision = 0.844\n",
      "Recall = 0.8131021194605009\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "print('F1 score =', f1_score(y_pred, y_train))\n",
    "print('Precision =', precision_score(y_pred, y_train))\n",
    "print('Recall =', recall_score(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9iYbTuhk8Yc"
   },
   "source": [
    "The Neural Network is numerically the 2nd best classifier surprisingly. Given we do not have large amounts of data, we expected the test scores to be lowest. Again, the Training data performed better than the Test set but not overfitting as much as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPE_3Iylk8Yc"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBKncb3Ak8Yc"
   },
   "source": [
    "- The neural network is the best classifier taking into consideration the training and test scores and the amount of potential overfitting.\n",
    "- Although Random Forest classifier had the largest F1 scores, it overfit the data. \n",
    "\n",
    "\n",
    "- To further improve, gathering more data would be more helpful. Testing out more different paremeters with something like gridsearchcv if our computers were more powerful and could more easily handle more combinations of parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zuv8bTP2k8Yc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Barbara_Schmitz.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
